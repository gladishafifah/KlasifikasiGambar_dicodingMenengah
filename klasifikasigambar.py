# -*- coding: utf-8 -*-
"""KlasifikasiGambar

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xugEsM3-LQ6y1hEzebsrClxrIAwPztps
"""

!pip install opendatasets
import zipfile, os
import opendatasets as od
import pandas as pd
import numpy as np
from google.colab import files
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

import tensorflow as tf
from keras.models import Sequential
from keras.regularizers import l2
from tensorflow.keras import regularizers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import load_img, img_to_array
from tensorflow.keras.preprocessing.image import ImageDataGenerator

od.download(
    'https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset'
)

base_dir = '/content/vegetable-image-dataset/Vegetable Images/train'
os.listdir(base_dir)

#Print total images in scissors, paper, and rock files
print('Image Bottle Gourd amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Bottle_Gourd')))
print('Image Papaya amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Papaya')))
print('Image Carrot amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Carrot')))
print('Image Cucumber amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Cucumber')))
print('Image Bitter_Gourd amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Bitter_Gourd')))
print('Image Pumpkin amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Pumpkin')))
print('Image Potato amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Potato')))
print('Image Cauliflower amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Cauliflower')))
print('Image Capsicum amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Capsicum')))
print('Image Cabbage amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Cabbage')))
print('Image Broccoli amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Broccoli')))
print('Image Briinjal amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Brinjal')))
print('Image Tomato amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Tomato')))
print('Image Radish amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Radish')))
print('Image Bean amount :', len(os.listdir('/content/vegetable-image-dataset/Vegetable Images/train/Bean')))

# Image Augmentation for duplicating image
train_datagen = ImageDataGenerator(
    rescale=1./255,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split = 0.2
)

validation_datagen = ImageDataGenerator(
    rescale=1./255,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split = 0.2
)

#Create generator classifier
train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(224, 224),
    batch_size=32,
    shuffle=True,
    class_mode='categorical',
    subset = 'training'
)

validation_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(224, 224),
    batch_size=32,
    shuffle=True,
    class_mode='categorical',
    subset = 'validation'
)

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.93 and logs.get('val_accuracy') > 0.93):
      print('\n Accuracy sudah mencapai > 93%')
      self.model.stop_training = True

callbacks = myCallback()

model_layer = Sequential([
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(224, 224, 3)),
    tf.keras.layers.MaxPool2D((2,2), padding='valid'),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPool2D((2,2), padding='valid'),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPool2D((2,2), padding='valid'),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPool2D((2,2), padding='valid'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.016), activity_regularizer=regularizers.l1(0.006)),
    tf.keras.layers.Dense(15, activation='softmax')
])

model_layer.summary()

#Adding an optimizer
model_layer.compile(
    loss='categorical_crossentropy',
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=['accuracy']
)

#Train Model with DenseNet201
history = model_layer.fit(
    train_generator,
    epochs=30,
    validation_data = validation_generator,
    verbose=1,
    callbacks = [callbacks]
)

# Visualize accuracy and loss plot
accuracy     = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

loss         = history.history['loss']
val_loss     = history.history['val_loss']

plt.figure(figsize = (12, 4))
epochs = range(len(accuracy))

plt.subplot(1, 2, 1)
plt.plot(epochs, accuracy, label='Training Accuracy')
plt.plot(epochs, val_accuracy, label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')

plt.subplot(1, 2, 2)
plt.plot(epochs, loss, label='Training Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')

plt.show()

train_generator.class_indices

uploaded = files.upload()

for fn in uploaded.keys():

    # predicting images
    path = fn
    img = load_img(path, target_size=(224, 224))
    imgplot = plt.imshow(img)
    x = img_to_array(img)
    x = np.expand_dims(x, axis=0) # menambahkan 1 dimensi, axis menunjukkan jumlah kelas

    images = np.vstack([x])
    classes = model_layer.predict(images, batch_size=8)
    result = np.argmax(classes)
    print(fn)
    print(classes)

    if result == 0:
      print('the picture shows Bean')
    elif result == 1:
      print('the picture shows Bitter_Gourd')
    elif result == 2:
      print('the picture shows Bottle_Gourd')
    elif result == 3:
      print('the picture shows Brinjal')
    elif result == 4:
      print('the picture shows Broccoli')
    elif result == 5:
      print('the picture shows Cabbage')
    elif result == 6:
      print('the picture shows Capsicum')
    elif result == 7:
      print('the picture shows Carrot')
    elif result == 8:
      print('the picture shows Cauliflower')
    elif result == 9:
      print('the picture shows Cucumber')
    elif result == 10:
      print('the picture shows Papaya')
    elif result == 11:
      print('the picture shows Potato')
    elif result == 12:
      print('the picture shows Pumpkin')
    elif result == 13:
      print('the picture shows Radish')
    else:
      print('your hand shows the Tomato')

# Save model to SavedModel format
exportDir = 'saved_model/'
tf.saved_model.save(model_layer, exportDir)

# Convert model to TF-Lite format
converter    = tf.lite.TFLiteConverter.from_saved_model(exportDir)
tflite_model = converter.convert()

# Save the model
with open('model.tflite', 'wb') as t:
    t.write(tflite_model)

print(f'Model TFLite berhasil disimpan di: {tflite_model}')